{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\LENOVO\\.cache\\kagglehub\\datasets\\lakshmi25npathi\\imdb-dataset-of-50k-movie-reviews\\versions\\1\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "#Wczytanie dokumentu\n",
    "import os  \n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "csv_path = os.path.join(path, \"IMDB Dataset.csv\")\n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(f\"Plik {csv_path} nie istnieje. Sprawdź nazwę pliku i ścieżkę.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcja czyszcząca do lematyzacji tekstu i usuwania interpunkcji, słów stop, białych znaków \n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def clean(text):\n",
    "    doc = nlp(text)\n",
    "    doc_cleaned = [\n",
    "        token for token in doc \n",
    "        if not (token.is_punct or token.is_stop or token.is_space or token.is_bracket)\n",
    "    ]\n",
    "    doc_lemmatized = [token.lemma_ for token in doc_cleaned]\n",
    "    text_lemmatized = \" \".join(doc_lemmatized)\n",
    "    \n",
    "    return text_lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Czyszczenie tekstów: 100%|██████████| 50000/50000 [31:30<00:00, 26.44it/s]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reviewer mention watch 1 Oz episode hook right...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production br /&gt;&lt;br /&gt;the fil...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy Jake think zombie ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei love Time money visually stunnin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  reviewer mention watch 1 Oz episode hook right...  positive\n",
       "1  wonderful little production br /><br />the fil...  positive\n",
       "2  think wonderful way spend time hot summer week...  positive\n",
       "3  basically family little boy Jake think zombie ...  negative\n",
       "4  Petter Mattei love Time money visually stunnin...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"Czyszczenie tekstów\")  \n",
    "df['review'] = df['review'].progress_apply(clean)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wektoryzacja tekstu za pomocą TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tqdm.pandas(desc=\"Wektoryzacja\")  \n",
    "text_vectorized = tfidf_vectorizer.fit_transform(df['review'])  \n",
    "x = text_vectorized\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wektoryzacja tekstu za pomocą CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "text_vectorized = count_vectorizer.fit_transform(df['review'])\n",
    "x = text_vectorized\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wektoryzacja tekstu za pomocą HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hashing_vectorizer = HashingVectorizer(n_features=5000) \n",
    "text_vectorized = hashing_vectorizer.fit_transform(df['review'])\n",
    "x = text_vectorized\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macierz pomyłek na zbiorze treningowym:\n",
      "[[10401  2099]\n",
      " [ 1054 11446]]\n",
      "Macierz pomyłek na zbiorze testowym:\n",
      "[[ 9913  2587]\n",
      " [ 1567 10933]]\n",
      "Raport klasyfikacji na zbiorze treningowym:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87     12500\n",
      "    positive       0.85      0.92      0.88     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.88      0.87      0.87     25000\n",
      "weighted avg       0.88      0.87      0.87     25000\n",
      "\n",
      "Raport klasyfikacji na zbiorze testowym:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83     12500\n",
      "    positive       0.81      0.87      0.84     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.84      0.83      0.83     25000\n",
      "weighted avg       0.84      0.83      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model 1 RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=42,stratify=y)\n",
    "\n",
    "# Inicjalizacja klasyfikatora Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "\n",
    "# Trenowanie modelu na zbiorze treningowym\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predykcja \n",
    "y_predicted_train = rf_classifier.predict(x_train)\n",
    "y_predicted_test = rf_classifier.predict(x_test)\n",
    "\n",
    "print(\"Macierz pomyłek na zbiorze treningowym:\")\n",
    "print(confusion_matrix(y_train, y_predicted_train))\n",
    "print(\"Macierz pomyłek na zbiorze testowym:\")\n",
    "print(confusion_matrix(y_test, y_predicted_test))\n",
    "print(\"Raport klasyfikacji na zbiorze treningowym:\")\n",
    "print(classification_report(y_train, y_predicted_train))\n",
    "print(\"Raport klasyfikacji na zbiorze testowym:\")\n",
    "print(classification_report(y_test, y_predicted_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macierz pomyłek na zbiorze treningowym:\n",
      "[[11525   975]\n",
      " [  746 11754]]\n",
      "Macierz pomyłek na zbiorze testowym:\n",
      "[[10852  1648]\n",
      " [ 1209 11291]]\n",
      "Raport klasyfikacji na zbiorze treningowym:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93     12500\n",
      "    positive       0.92      0.94      0.93     12500\n",
      "\n",
      "    accuracy                           0.93     25000\n",
      "   macro avg       0.93      0.93      0.93     25000\n",
      "weighted avg       0.93      0.93      0.93     25000\n",
      "\n",
      "Raport klasyfikacji na zbiorze testowym:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.88     12500\n",
      "    positive       0.87      0.90      0.89     12500\n",
      "\n",
      "    accuracy                           0.89     25000\n",
      "   macro avg       0.89      0.89      0.89     25000\n",
      "weighted avg       0.89      0.89      0.89     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model 2 LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=42, stratify=y)\n",
    "\n",
    "# Inicjalizacja klasyfikatora Logistic Regression\n",
    "lr_classifier = LogisticRegression(solver='saga', random_state=42)\n",
    "\n",
    "# Trenowanie modelu na zbiorze treningowym\n",
    "lr_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predykcja \n",
    "y_predicted_train = lr_classifier.predict(x_train)\n",
    "y_predicted_test = lr_classifier.predict(x_test)\n",
    "\n",
    "print(\"Macierz pomyłek na zbiorze treningowym:\")\n",
    "print(confusion_matrix(y_train, y_predicted_train))\n",
    "print(\"Macierz pomyłek na zbiorze testowym:\")\n",
    "print(confusion_matrix(y_test, y_predicted_test))\n",
    "print(\"Raport klasyfikacji na zbiorze treningowym:\")\n",
    "print(classification_report(y_train, y_predicted_train))\n",
    "print(\"Raport klasyfikacji na zbiorze testowym:\")\n",
    "print(classification_report(y_test, y_predicted_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macierz pomyłek na zbiorze treningowym:\n",
      "[[12398   102]\n",
      " [  105 12395]]\n",
      "Macierz pomyłek na zbiorze testowym:\n",
      "[[10899  1601]\n",
      " [ 1156 11344]]\n",
      "Raport klasyfikacji na zbiorze treningowym:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99     12500\n",
      "    positive       0.99      0.99      0.99     12500\n",
      "\n",
      "    accuracy                           0.99     25000\n",
      "   macro avg       0.99      0.99      0.99     25000\n",
      "weighted avg       0.99      0.99      0.99     25000\n",
      "\n",
      "Raport klasyfikacji na zbiorze testowym:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89     12500\n",
      "    positive       0.88      0.91      0.89     12500\n",
      "\n",
      "    accuracy                           0.89     25000\n",
      "   macro avg       0.89      0.89      0.89     25000\n",
      "weighted avg       0.89      0.89      0.89     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model 3 SVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=42, stratify=y)\n",
    "\n",
    "# Inicjalizacja klasyfikatora Support Vector Machine\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Trenowanie modelu na zbiorze treningowym\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predykcja \n",
    "y_predicted_train = svm_classifier.predict(x_train)\n",
    "y_predicted_test = svm_classifier.predict(x_test)\n",
    "\n",
    "print(\"Macierz pomyłek na zbiorze treningowym:\")\n",
    "print(confusion_matrix(y_train, y_predicted_train))\n",
    "print(\"Macierz pomyłek na zbiorze testowym:\")\n",
    "print(confusion_matrix(y_test, y_predicted_test))\n",
    "print(\"Raport klasyfikacji na zbiorze treningowym:\")\n",
    "print(classification_report(y_train, y_predicted_train))\n",
    "print(\"Raport klasyfikacji na zbiorze testowym:\")\n",
    "print(classification_report(y_test, y_predicted_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      5\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtqdm\u001b[49m\u001b[38;5;241m.\u001b[39mpandas(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWektoryzacja\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[0;32m      7\u001b[0m vectorized_text \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m])  \n\u001b[0;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m vectorized_text\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Wektoryzacja tekstu za pomocą TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tqdm.pandas(desc=\"Wektoryzacja\")  \n",
    "vectorized_text = tfidf_vectorizer.fit_transform(df['review'])  \n",
    "x = vectorized_text\n",
    "y = df['sentiment']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=42, stratify=y)\n",
    "\n",
    "# Model 1: Logistic Regression\n",
    "lr_classifier = LogisticRegression(solver='saga', random_state=42)\n",
    "lr_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Model 2: Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Zapisywanie wektoryzatora\n",
    "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "# Zapisywanie modelu Logistic Regression\n",
    "with open(\"logistic_regression_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lr_classifier, f)\n",
    "\n",
    "# Zapisywanie modelu Random Forest\n",
    "with open(\"random_forest_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf_classifier, f)\n",
    "\n",
    "print(\"Modele i wektoryzator zostały zapisane.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import spacy\n",
    "import pickle\n",
    "\n",
    "# Funkcja czyszcząca do lematyzacji tekstu\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def clean_text(text):\n",
    "    doc = nlp(text)\n",
    "    doc_cleaned = [\n",
    "        token for token in doc\n",
    "        if not (token.is_punct or token.is_stop or token.is_space or token.is_bracket)\n",
    "    ]\n",
    "    doc_lemmatized = [token.lemma_ for token in doc_cleaned]\n",
    "    return \" \".join(doc_lemmatized)\n",
    "\n",
    "# Wczytanie modeli i wektoryzatora\n",
    "with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "\n",
    "with open(\"logistic_regression_model.pkl\", \"rb\") as f:\n",
    "    logistic_regression_model = pickle.load(f)\n",
    "\n",
    "with open(\"random_forest_model.pkl\", \"rb\") as f:\n",
    "    random_forest_model = pickle.load(f)\n",
    "\n",
    "# Funkcja do klasyfikacji tekstu\n",
    "def classify_text():\n",
    "    user_input = input_text.get(\"1.0\", tk.END).strip()\n",
    "    if not user_input:\n",
    "        result_label.config(text=\"Wprowadź recenzję do analizy.\")\n",
    "        return\n",
    "\n",
    "    cleaned_text = clean_text(user_input)\n",
    "    vectorized_text = tfidf_vectorizer.transform([cleaned_text])\n",
    "\n",
    "    # Predykcja przy użyciu modeli\n",
    "    sentiment_lr = logistic_regression_model.predict(vectorized_text)[0]\n",
    "    sentiment_rf = random_forest_model.predict(vectorized_text)[0]\n",
    "\n",
    "    # Wyświetlenie wyników\n",
    "    result_label.config(\n",
    "        text=f\"Sentyment wg Logistic Regression: {'Pozytywny' if sentiment_lr == 'positive' else 'Negatywny'}\\n\"\n",
    "             f\"Sentyment wg Random Forest: {'Pozytywny' if sentiment_rf == 'positive' else 'Negatywny'}\"\n",
    "    )\n",
    "\n",
    "# GUI aplikacji\n",
    "app = tk.Tk()\n",
    "app.title(\"Analiza Sentymentu\")\n",
    "app.geometry(\"500x400\")\n",
    "\n",
    "# Etykiety i pola tekstowe\n",
    "label = tk.Label(app, text=\"Wprowadź recenzję:\", font=(\"Arial\", 14))\n",
    "label.pack(pady=10)\n",
    "\n",
    "input_text = tk.Text(app, height=10, width=50)\n",
    "input_text.pack(pady=10)\n",
    "\n",
    "classify_button = ttk.Button(app, text=\"Analizuj\", command=classify_text)\n",
    "classify_button.pack(pady=10)\n",
    "\n",
    "result_label = tk.Label(app, text=\"\", font=(\"Arial\", 12), justify=\"left\")\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "app.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
